{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Data Loaded:\n",
      "         Date       AAPL     AMZN      GOOGL         IBM       META  \\\n",
      "0  2015-01-02  24.347170  15.4260  26.381865  100.658279  78.151474   \n",
      "1  2015-01-05  23.661274  15.1095  25.879185   99.074463  76.896263   \n",
      "2  2015-01-06  23.663502  14.7645  25.240503   96.937805  75.860222   \n",
      "3  2015-01-07  23.995316  14.9210  25.166271   96.304253  75.860222   \n",
      "4  2015-01-08  24.917269  15.0230  25.253954   98.397438  77.882492   \n",
      "\n",
      "        MSFT       NFLX      NVDA       ORCL  ...     AAPL.5    AMZN.5  \\\n",
      "0  40.152485  49.848572  0.483143  37.863850  ...  212818400  55664000   \n",
      "1  39.783253  47.311428  0.474983  37.332840  ...  257142000  55484000   \n",
      "2  39.199337  46.501431  0.460582  36.947441  ...  263188400  70380000   \n",
      "3  39.697376  46.742859  0.459382  36.956005  ...  160423600  52806000   \n",
      "4  40.865208  47.779999  0.476663  37.178692  ...  237458000  61768000   \n",
      "\n",
      "    GOOGL.5    IBM.5    META.5    MSFT.5    NFLX.5     NVDA.5    ORCL.5  \\\n",
      "0  26480000  5779673  18177500  27913900  13475000  113680000  15070200   \n",
      "1  41182000  5104898  26452200  39673900  18165000  197952000  18369400   \n",
      "2  54456000  6429448  27399300  36447900  16037700  197764000  19229500   \n",
      "3  46918000  4918083  22045300  29114100   9849700  321808000  13502200   \n",
      "4  73054000  4431693  23961000  29645200   9601900  283780000  17516900   \n",
      "\n",
      "     TSLA.5  \n",
      "0  71466000  \n",
      "1  80527500  \n",
      "2  93928500  \n",
      "3  44526000  \n",
      "4  51637500  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "\n",
      "JSON Data Loaded:\n",
      "            AAPL_Adj Close  AAPL_Close  AAPL_High   AAPL_Low  AAPL_Open  \\\n",
      "2020-01-02       72.796013   75.087502  75.150002  73.797501  74.059998   \n",
      "2020-01-03       72.088287   74.357498  75.144997  74.125000  74.287498   \n",
      "2020-01-06       72.662720   74.949997  74.989998  73.187500  73.447502   \n",
      "2020-01-07       72.320969   74.597504  75.224998  74.370003  74.959999   \n",
      "2020-01-08       73.484360   75.797501  76.110001  74.290001  74.290001   \n",
      "\n",
      "            AAPL_Volume  AMZN_Adj Close  AMZN_Close  AMZN_High   AMZN_Low  \\\n",
      "2020-01-02    135480400       94.900497   94.900497  94.900497  93.207497   \n",
      "2020-01-03    146322800       93.748497   93.748497  94.309998  93.224998   \n",
      "2020-01-06    118387200       95.143997   95.143997  95.184502  93.000000   \n",
      "2020-01-07    108872000       95.343002   95.343002  95.694504  94.601997   \n",
      "2020-01-08    132079200       94.598503   94.598503  95.550003  94.321999   \n",
      "\n",
      "            ...  ORCL_High   ORCL_Low  ORCL_Open  ORCL_Volume  TSLA_Adj Close  \\\n",
      "2020-01-02  ...  53.959999  53.230000  53.270000     13899600       28.684000   \n",
      "2020-01-03  ...  54.049999  52.950001  52.990002     11026700       29.534000   \n",
      "2020-01-06  ...  54.200001  53.349998  53.360001     10982400       30.102667   \n",
      "2020-01-07  ...  54.330002  53.610001  53.889999     12015400       31.270666   \n",
      "2020-01-08  ...  54.599998  53.700001  53.939999     11856700       32.809334   \n",
      "\n",
      "            TSLA_Close  TSLA_High   TSLA_Low  TSLA_Open  TSLA_Volume  \n",
      "2020-01-02   28.684000  28.713333  28.114000  28.299999    142981500  \n",
      "2020-01-03   29.534000  30.266666  29.128000  29.366667    266677500  \n",
      "2020-01-06   30.102667  30.104000  29.333332  29.364668    151995000  \n",
      "2020-01-07   31.270666  31.441999  30.224001  30.760000    268231500  \n",
      "2020-01-08   32.809334  33.232666  31.215334  31.580000    467164500  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base directories\n",
    "base_dir = \"../\"  # Base directory, relative to the notebook\n",
    "processed_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
    "\n",
    "# Define file paths \n",
    "cleaned_csv_path = os.path.join(processed_dir, \"cleaned_stock_data.csv\")\n",
    "cleaned_json_path = os.path.join(processed_dir, \"cleaned_stock_data.json\")\n",
    "\n",
    "# Access the cleaned CSV file\n",
    "df_cleaned_csv = pd.read_csv(cleaned_csv_path)\n",
    "print(\"CSV Data Loaded:\")\n",
    "print(df_cleaned_csv.head())\n",
    "\n",
    "# Access the cleaned JSON file\n",
    "df_cleaned_json = pd.read_json(cleaned_json_path)\n",
    "print(\"\\nJSON Data Loaded:\")\n",
    "print(df_cleaned_json.head())\n",
    "\n",
    "\n",
    "final_merged_path  = os.path.join(processed_dir, \"final_merged_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚úÖ Step 1: Load Cleaned Data\n",
    "df_csv = pd.read_csv(cleaned_csv_path)\n",
    "df_json = pd.read_json(cleaned_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç JSON Columns: Index(['AAPL_Adj Close', 'AAPL_Close', 'AAPL_High', 'AAPL_Low', 'AAPL_Open',\n",
      "       'AAPL_Volume', 'AMZN_Adj Close', 'AMZN_Close', 'AMZN_High', 'AMZN_Low',\n",
      "       'AMZN_Open', 'AMZN_Volume', 'GOOGL_Adj Close', 'GOOGL_Close',\n",
      "       'GOOGL_High', 'GOOGL_Low', 'GOOGL_Open', 'GOOGL_Volume',\n",
      "       'IBM_Adj Close', 'IBM_Close', 'IBM_High', 'IBM_Low', 'IBM_Open',\n",
      "       'IBM_Volume', 'META_Adj Close', 'META_Close', 'META_High', 'META_Low',\n",
      "       'META_Open', 'META_Volume', 'MSFT_Adj Close', 'MSFT_Close', 'MSFT_High',\n",
      "       'MSFT_Low', 'MSFT_Open', 'MSFT_Volume', 'NFLX_Adj Close', 'NFLX_Close',\n",
      "       'NFLX_High', 'NFLX_Low', 'NFLX_Open', 'NFLX_Volume', 'NVDA_Adj Close',\n",
      "       'NVDA_Close', 'NVDA_High', 'NVDA_Low', 'NVDA_Open', 'NVDA_Volume',\n",
      "       'ORCL_Adj Close', 'ORCL_Close', 'ORCL_High', 'ORCL_Low', 'ORCL_Open',\n",
      "       'ORCL_Volume', 'TSLA_Adj Close', 'TSLA_Close', 'TSLA_High', 'TSLA_Low',\n",
      "       'TSLA_Open', 'TSLA_Volume'],\n",
      "      dtype='object')\n",
      "üîç JSON Index Name: None\n",
      "            AAPL_Adj Close  AAPL_Close  AAPL_High   AAPL_Low  AAPL_Open  \\\n",
      "2020-01-02       72.796013   75.087502  75.150002  73.797501  74.059998   \n",
      "2020-01-03       72.088287   74.357498  75.144997  74.125000  74.287498   \n",
      "2020-01-06       72.662720   74.949997  74.989998  73.187500  73.447502   \n",
      "2020-01-07       72.320969   74.597504  75.224998  74.370003  74.959999   \n",
      "2020-01-08       73.484360   75.797501  76.110001  74.290001  74.290001   \n",
      "\n",
      "            AAPL_Volume  AMZN_Adj Close  AMZN_Close  AMZN_High   AMZN_Low  \\\n",
      "2020-01-02    135480400       94.900497   94.900497  94.900497  93.207497   \n",
      "2020-01-03    146322800       93.748497   93.748497  94.309998  93.224998   \n",
      "2020-01-06    118387200       95.143997   95.143997  95.184502  93.000000   \n",
      "2020-01-07    108872000       95.343002   95.343002  95.694504  94.601997   \n",
      "2020-01-08    132079200       94.598503   94.598503  95.550003  94.321999   \n",
      "\n",
      "            ...  ORCL_High   ORCL_Low  ORCL_Open  ORCL_Volume  TSLA_Adj Close  \\\n",
      "2020-01-02  ...  53.959999  53.230000  53.270000     13899600       28.684000   \n",
      "2020-01-03  ...  54.049999  52.950001  52.990002     11026700       29.534000   \n",
      "2020-01-06  ...  54.200001  53.349998  53.360001     10982400       30.102667   \n",
      "2020-01-07  ...  54.330002  53.610001  53.889999     12015400       31.270666   \n",
      "2020-01-08  ...  54.599998  53.700001  53.939999     11856700       32.809334   \n",
      "\n",
      "            TSLA_Close  TSLA_High   TSLA_Low  TSLA_Open  TSLA_Volume  \n",
      "2020-01-02   28.684000  28.713333  28.114000  28.299999    142981500  \n",
      "2020-01-03   29.534000  30.266666  29.128000  29.366667    266677500  \n",
      "2020-01-06   30.102667  30.104000  29.333332  29.364668    151995000  \n",
      "2020-01-07   31.270666  31.441999  30.224001  30.760000    268231500  \n",
      "2020-01-08   32.809334  33.232666  31.215334  31.580000    467164500  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load JSON\n",
    "df_json = pd.read_json(cleaned_json_path)\n",
    "\n",
    "# Print available columns\n",
    "print(\"üîç JSON Columns:\", df_json.columns)\n",
    "print(\"üîç JSON Index Name:\", df_json.index.name)\n",
    "print(df_json.head())  # Preview the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ **Fix: Convert JSON Index to \"Date\" Column**\n",
    "df_json = df_json.reset_index().rename(columns={\"index\": \"Date\"})\n",
    "\n",
    "# ‚úÖ Step 2: Ensure Proper Date Formatting\n",
    "df_csv[\"Date\"] = pd.to_datetime(df_csv[\"Date\"], errors=\"coerce\")\n",
    "df_json[\"Date\"] = pd.to_datetime(df_json[\"Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 3: Align Date Ranges\n",
    "min_date = min(df_csv[\"Date\"].min(), df_json[\"Date\"].min())\n",
    "max_date = max(df_csv[\"Date\"].max(), df_json[\"Date\"].max())\n",
    "date_range = pd.date_range(start=min_date, end=max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_csv.set_index(\"Date\").reindex(date_range).reset_index().rename(columns={\"index\": \"Date\"}).ffill()\n",
    "df_json = df_json.set_index(\"Date\").reindex(date_range).reset_index().rename(columns={\"index\": \"Date\"}).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 4: Merge Cleaned Data\n",
    "merged_df = pd.merge(df_csv, df_json, on=\"Date\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Step 5: Fill Missing Values\n",
    "merged_df.ffill(inplace=True)  # Forward fill\n",
    "merged_df.bfill(inplace=True)  # Backward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final Merged Stock Data saved at: ../data/processed/final_merged_stock_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 6: Save the Final Cleaned Data\n",
    "merged_df.to_csv(final_merged_path, index=False)\n",
    "print(f\"‚úÖ Final Merged Stock Data saved at: {final_merged_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
